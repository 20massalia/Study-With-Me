# 메모리 관리

운영체제에서 메모리 관리는 한정된 물리 메모리를 여러 프로세스가 안전하고 효율적으로 공유하도록 하는 핵심 기능입니다.

<br/>

## 가상 메모리

### 개념

가상 메모리는 각각의 프로세스에 독립적이고 연속적인 주소 공간을 제공하면서 실제 물리적 메모리의 한계를 넘어서는 효과를 냅니다.

프로세스는 자신만의 “가상 주소”를 사용하고, 이 주소는 실행 시점에 운영체제와 하드웨어가 변환하여 실제 물리 메모리에 대응시킵니다.

이를 통해 주소 공간 분리, 보호, 메모리 활용의 유연성을 확보합니다.

### 동작 원리

1. 주소 바인딩 시점

- **컴파일 시 바인딩**: 코드가 컴파일될 때 주소가 결정됩니다. 실제 현대 일반 목적 시스템에서는 잘 쓰이지 않습니다.
- **로딩 시 바인딩**: 실행 파일이 메모리에 로드될 때 재배치되어 물리 주소가 결정됩니다.
- **실행 시 바인딩**: 논리(가상) 주소를 물리 주소로 변환하는 작업이 실행 중에 이루어지며, MMU가 이를 담당합니다. 이 방식은 가장 유연하며 재배치 없이도 프로세스간 주소 독립성을 준수할 수 있습니다.

2. 주소 변환 구조

- **페이지 테이블**: 가상 페이지 번호와 물리 프레임 번호를 매핑하는 구조입니다. 프로세스마다 별도의 페이지 테이블이 존재합니다.
- **다단계 페이징**: 대형 주소 공간에서 전체 페이지 테이블을 메모리에 올리는 비용을 줄이기 위해 계층적으로 나누어 필요한 부분만 인스턴스화합니다.
- **TLB (Translation Lookaside Buffer)**: 최근에 사용된 가상→물리 매핑을 캐시하여 주소 변환을 고속화합니다. TLB 미스가 발생하면 페이지 테이블을 순차적으로 조회해야 하므로 비용이 증가합니다.
- **베이스/리밋 방식** (단순한 실행 시 바인딩 모델): 가상 주소에 단순한 오프셋을 더하여 물리 주소를 얻고, 리밋 검사로 범위 초과 접근을 차단합니다.

### 페이징과 세그멘테이션

- **페이징**: 가상 주소 공간과 물리 주소 공간을 동일 크기의 블록(페이지/프레임)으로 나누어 매핑합니다. 외부 단편화가 제거되지만, 페이지 내부에 쓰지 않는 공간이 있어 내부 단편화는 존재할 수 있습니다.
- **세그멘테이션**: 논리적 단위(코드, 데이터, 스택 등)로 메모리를 분할합니다. 각 세그먼트는 크기가 유동적이어서 내부 단편화는 적지만 외부 단편화가 생깁니다.
- **페이징 + 세그멘테이션 결합**: 세그먼트 내부를 다시 페이징으로 나누는 방식으로 두 방식의 장점을 조합합니다.

### 페이지 폴트

프로세스가 참조한 가상 페이지가 물리 메모리에 올라와 있지 않으면 페이지 폴트가 발생합니다. 처리 순서는 일반적으로 다음과 같습니다:

1. CPU가 접근한 가상 주소가 페이지 테이블에 없음을 감지 (valid bit 검사)
2. 운영체제가 페이지 폴트 인터럽트를 받음
3. 교체 대상 프레임 결정 (필요하다면 페이지 교체 알고리즘 실행)
4. 디스크(스왑 공간 또는 백킹 스토어)에서 필요한 페이지를 읽어 물리 메모리에 적재
5. 페이지 테이블과 TLB 갱신
6. 원래 명령 재시도

### 스와핑

메모리 전체 또는 일부를 디스크로 옮겨(스왑 아웃) 현재 활성화할 수 있는 메모리 슬롯을 확보하고, 나중에 다시 불러오는(스왑 인) 방식입니다. 주기억장치가 부족한 멀티프로그래밍 환경에서 일시적으로 프로세스를 메모리 밖으로 밀어냄으로써 공간을 확보합니다.

### 지역성 원칙과 워킹셋

- **지역성(Locality)**: 시간적 지역성(최근 사용된 데이터가 곧 다시 사용됨), 공간적 지역성(인접 주소가 곧 사용됨) 개념을 기반으로 캐시 및 페이지 교체 전략이 설계됩니다.
- **워킹셋(Working Set)**: 최근 일정 시간 동안 프로세스가 참조한 페이지 집합으로, 이 집합을 충분히 메모리에 유지하면 페이지 폴트율이 낮아집니다. 워킹셋을 동적으로 추적하여 스래싱(thrashing)을 방지할 수 있습니다.

### 장점

- 각각의 프로세스에 독립된 주소 공간 제공
- 물리 메모리보다 큰 가상 공간으로 큰 프로그램 실행 가능
- 수요 페이징, 동적 로딩, 오버레이 등의 기법으로 메모리 효율 증대
- 메모리 보호 및 프로세스 간 간섭 방지

<br/>

## 스레딩

### 개념

스레드는 프로세스 내부의 실행 단위입니다. 하나의 프로세스가 여러 스레드를 가지면 각 스레드는 독립적으로 실행 흐름을 가지면서도 동일한 주소 공간(코드/데이터/힙)을 공유합니다. 스레드는 경량화된 문맥, 빠른 생성/전환으로 병행 처리 효율을 높입니다.

### 메모리 관계

- 공유: 코드 영역, 전역 데이터, 힙
- 독립: 스택, 레지스터 컨텍스트
  스레드 간 동시 접근이 일어나면 동기화 문제가 발생하므로 뮤텍스, 세마포어 등의 동기화 메커니즘이 필요합니다.

### 장점

- 문맥 교환 비용이 프로세스보다 낮음
- 자원을 공유하여 메모리 사용 효율 증가
- 병렬 작업 처리 시 응답성 향상

### 운영체제 역할

- 스레드 스케줄링 (커널 스레드 vs 사용자 스레드 모델)
- 동기화 프리미티브 제공
- 스레드별 상태와 권한 관리
- 스레드 간 자원 접근 보호

<br/>

## 메모리 할당

### 할당 전략

1. **고정 분할 (Fixed Partitioning)**
   - 메모리를 사전에 정해진 크기의 블록으로 나누어 프로세스에 할당합니다.
   - 내부 단편화가 생기며, 프로세스 크기 변화에는 융통성이 낮습니다.
2. **가변 분할 (Variable Partitioning)**
   - 프로세스 크기에 맞춰 블록을 동적으로 생성합니다.
   - 외부 단편화가 발생할 수 있으며, 이를 줄이기 위해 **컴팩션(compaction)**이 필요할 수 있습니다.
   - 할당 알고리즘
     - **First-fit**: 처음 맞는 공간
     - **Next-fit**: 이전 할당 위치 이후로 검색
     - **Best-fit**: 가장 작은 적합 공간
     - **Worst-fit**: 가장 큰 공간
3. **버디 시스템 (Buddy System)**
   - 크기가 2ⁿ인 블록 단위로 분할/합병합니다.
   - 할당 시 가장 작은 2ⁿ 크기를 선택하며, 해제 시 인접한 “버디” 블록과 합쳐 공간을 회수해 외부 단편화를 줄입니다.

### 할당 방식

- **연속 할당 (Contiguous Allocation)**: 프로세스가 메모리 상에서 연속된 영역을 차지합니다.
- **비연속 할당 (Non-contiguous Allocation)**: 페이징이나 세그멘테이션을 이용해 여러 조각에 분산 저장합니다.

### 동적 할당과 해제

런타임 시 요구에 따라 힙 영역에서 메모리를 할당하고 반환하며, 메모리 누수나 단편화가 누적되지 않도록 관리해야 합니다.

### 멀티프로그래밍 환경 고려사항

운영체제는 다양한 프로세스의 메모리 요구를 동시에 충족시키기 위해 다음을 관리합니다:

- 보호 (다른 프로세스 접근 차단)
- 공유 (공통 코드/라이브러리)
- 단편화 감소
- 전체 사용률 균형

<br/>

## 페이지 교체 알고리즘

### 필요성

물리 메모리가 꽉 찬 상황에서 새로운 페이지를 적재하려면 기존에 메모리에 있던 페이지 중 하나를 내보내야 합니다. 어떤 페이지를 교체할지 결정하는 정책이 성능에 큰 영향을 줍니다.

### 주요 알고리즘

- **FIFO (First-In First-Out)**
  가장 먼저 들어온 페이지를 교체합니다. 구현이 쉽지만, 오래된 페이지라도 자주 쓰이면 비효율적일 수 있습니다.
- **LRU (Least Recently Used)**
  가장 오랫동안 사용되지 않은 페이지를 교체합니다. 최근성(locality)을 활용하므로 효율적이나 정확한 구현에는 시간 또는 공간 오버헤드(Timestamp, 스택, 카운터 등)가 발생합니다.
- **Optimal**
  앞으로 가장 오랫동안 참조되지 않을 페이지를 교체합니다. 이론적으로 최적인 방법이나 미래 참조를 미리 알 수 없으므로 실질적으로 구현 불가능하며 비교 기준으로 사용됩니다.
- **Clock (Second Chance)**
  FIFO의 간단한 구현을 개선한 방식으로, 각 페이지에 참조 비트를 두고 손잡이처럼 순환하면서 참조 비트가 0인 페이지를 교체합니다. 참조 비트가 1이면 0으로 바꾸고 한 바퀴 더 돌립니다.
- **LFU (Least Frequently Used)**
  참조 횟수가 가장 적은 페이지를 교체합니다. 장기적으로 잘 사용되지 않는 페이지를 제거하지만, 최근에 방금 참조된 페이지가 아닌데도 낮은 빈도로 인해 교체될 수 있습니다.
- **Aging / Approximate LRU**
  참조 비트들을 시프트하면서 사용 빈도의 시간적 감쇠를 반영하여 LRU를 근사합니다.

### 선택 기준

- 구현 복잡도
- 오버헤드 (추적을 위한 추가 구조 비용)
- 실제 프로그램의 참조 패턴 (지역성, 워킹셋 크기)
- 스래싱(thrashing) 대응 능력

### 스래싱과 예방

프로세스들이 필요한 워킹셋보다 적은 페이지를 갖고 경쟁하면 과도한 페이지 폴트가 발생해 전체 성능이 급격히 떨어지는 스래싱이 발생합니다. 운영체제는 워킹셋 모델이나 로드 컨트롤(load control)로 적절한 프로세스 수를 유지해 이를 방지합니다.

### 운영체제 역할

- 페이지 폴트 발생 시 적절한 교체 알고리즘 적용
- 워킹셋 모니터링
- 스래싱 감지 및 제어 (예: 프로세스 수 제한, 축소 전략)

<br/>
<br/>

> 참고
>
> - https://rebro.kr/178
> - https://letsmakemyselfprogrammer.tistory.com/116
> - https://myvelop.tistory.com/201
