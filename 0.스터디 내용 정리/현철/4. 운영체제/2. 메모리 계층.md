# 메모리
메모리(RAM, Random Access Memory)는 프로그램이 실행 중일 때 데이터를 일시적으로 저장하는 공간. 컴퓨터를 켜면 운영체제와 실행 중인 프로그램의 코드, 변수, 연산 결과 등이 모두 메모리에 올라가고 CPU는 이 메모리에 접근해 데이터를 읽고 쓰며 작업을 수행한다.

메모리의 특징
- 휘발성(Volatile): 전원이 꺼지면 모든 데이터가 사라짐
- 고속 액세스: SSD나 HDD보다 훨씬 빠르게 데이터에 접근할 수 있음
- 실행 공간: 실행 중인 프로그램과 관련된 모든 작업이 이곳에서 이루어짐

## 메모리 계층 구조
컴퓨터는 속도가 빠를수록 비싸고, 크기가 작아지는 특성이 있는 다양한 종류의 저장 장치를 조합해 사용하는데 이들을 빠른 순서대로 정리한 것이 바로 메모리 계층 구조.

```text
빠름 ↑ ───────────────────────────────  
       레지스터 (Register)  
       L1 캐시  
       L2 캐시  
       L3 캐시  
       주기억장치 (RAM)  
       SSD / HDD  
느림 ↓ ───────────────────────────────  
```
- 레지스터: CPU 내부에 있는 초고속 저장소. 매우 작고 매우 빠름
- 캐시(Cache): CPU 가까이에 있는 메모리로, 주 메모리보다 빠르지만 용량이 작음
- RAM (Main Memory): 우리가 흔히 말하는 "메모리". 비교적 빠르고 용량이 큼
- SSD / HDD: 비휘발성 저장 장치. 가장 느리지만, 가장 큰 용량을 제공

즉, 속도는 빠를수록 용량이 작고 비싸며, 느릴수록 용량이 크고 싸다. 운영체제와 하드웨어는 이 계층을 활용해 데이터를 가장 빠른 위치에서 찾을 수 있도록 최적화한다.

## 캐시
캐시는 CPU와 메모리 사이에 위치한 고속 임시 저장소. 자주 접근하는 데이터를 미리 저장해 CPU가 RAM까지 가지 않고도 빠르게 데이터를 가져올 수 있게 한다.

### 캐시가 필요한 이유
- RAM은 CPU보다 느리다
- 만약 CPU가 매번 RAM에서 데이터를 가져온다면, 계산보다 대기 시간이 더 길어진다
- 캐시는 최근에 사용된 데이터를 저장해, “다시 필요할 확률이 높은 데이터”를 가까운 곳에 두는 전략을 사용

이 개념을 지역성(Locality)이라고 한다.

### 지역성의 원리
1. 시간 지역성 (Temporal Locality)
    - 최근 사용된 데이터는 다시 사용될 가능성이 높음
    - 예: 반복문 안의 변수
2. 공간 지역성 (Spatial Locality)
    - 인접한 주소의 데이터가 함께 사용될 가능성이 높음
    - 예: 배열 순회

### CPU 캐시의 계층 구조
| 계층        | 위치          | 속도    | 크기              | 공유 여부    |
| --------- | ----------- | ----- | --------------- | -------- |
| **L1 캐시** | CPU 코어 내부   | 가장 빠름 | 작음 (32\~64KB)   | 코어 전용    |
| **L2 캐시** | CPU 코어 내부   | 빠름    | 중간 (256KB\~1MB) | 코어 전용    |
| **L3 캐시** | CPU 외부 (공유) | 느림    | 큼 (4\~32MB)     | 모든 코어 공유 |

### 캐시 미스와 캐시 적중
- 캐시 히트 (Cache Hit): CPU가 찾는 데이터가 캐시에 있음 → 빠르게 처리 가능
- 캐시 미스 (Cache Miss): 데이터가 캐시에 없음 → 더 느린 메모리(RAM 또는 디스크)에서 불러옴

캐시 미스가 발생한다면
1. CPU가 RAM에 접근해서 데이터를 가져옴
2. 데이터를 캐시에 저장
3. 그 다음부터는 캐시에서 처리 가능

### 캐시 교체 알고리즘
캐시는 용량이 한정되어 있기 때문에, 새로운 데이터를 넣어야 할 때 기존 데이터 중 하나를 제거(evict) 해야 한다. 이때 어떤 데이터를 내보낼지 결정하는 규칙이 바로 캐시 교체 알고리즘이다.

1. FIFO (First-In, First-Out) : 가장 먼저 캐시에 들어온 데이터를 먼저 제거하는 방식
   - 원리: 선입선출 큐처럼 작동
   - 장점: 구현이 단순하고 빠름
   - 단점: 오래됐지만 여전히 자주 사용되는 데이터를 제거할 수 있음
2. LRU (Least Recently Used) : 가장 오랫동안 사용되지 않은 데이터를 제거하는 방식
   - 원리: “최근 사용된 것일수록 다시 사용될 가능성이 높다”는 시간 지역성(Temporal Locality) 기반
   - 장점: 실제 시스템에서 효과적인 경우가 많음
   - 단점: 사용 이력 추적을 위해 구현이 복잡 (예: 시간 스탬프, LinkedHashMap 등)
3. LFU (Least Frequently Used) : 가장 적게 사용된 데이터를 제거하는 방식
   - 원리: 자주 사용되는 데이터는 계속 사용될 가능성이 높다는 가정
   - 장점: 접근 빈도를 기준으로 판단 → 데이터 사용 패턴이 고정적일 때 효과적
   - 단점: 같은 횟수일 경우 우선순위 판단이 어렵고, 최근성이 반영되지 않음