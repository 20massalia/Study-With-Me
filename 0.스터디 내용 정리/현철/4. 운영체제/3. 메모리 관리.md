# 메모리 관리
운영체제에서 메모리 관리는 성능과 안정성을 좌우하는 핵심 기능 중 하나다. 실제로 모든 프로그램은 실행 중에 메모리를 사용하며, 운영체제는 이 메모리를 효율적이고 안전하게 관리해야 한다.

## 가상 메모리 (Virtual Memory)
가상 메모리는 운영체제가 제공하는 메모리 추상화 기법으로, 실제 메모리(RAM)의 크기보다 더 큰 메모리 공간을 프로그램이 사용하는 것처럼 보이게 만든다.

### 왜 필요할까?
- 프로그램마다 독립적인 주소 공간을 제공해 보안성과 안정성 향상
- 물리 메모리보다 큰 프로그램도 실행 가능 (디스크 일부를 활용)
- 프로세스 간 메모리 충돌 방지

### 핵심 개념
- 가상 주소(Virtual Address): 프로그램이 인식하는 주소
- 물리 주소(Physical Address): 실제 RAM의 주소
- 운영체제는 페이지 테이블(Page Table)을 통해 가상 주소를 물리 주소로 변환. 이를 주소 변환(Address Translation)이라고 함
```text
프로세스 A: 가상 주소 0x0000 ~ 0xFFFF  
프로세스 B: 가상 주소 0x0000 ~ 0xFFFF  
→ 서로 같은 주소를 쓰지만, 실제 물리 메모리는 완전히 다름
```

## 스레딩 (Threading)
스레드(Thread)는 프로세스 내에서 실행되는 최소 실행 단위

| 항목     | 프로세스(Process) | 스레드(Thread) |
| ------ | ------------- | ----------- |
| 메모리 공간 | 각각 독립         | 같은 공간 공유    |
| 생성 비용  | 큼             | 작음          |
| 통신 방식  | IPC 필요        | 공유 변수 사용 가능 |

### 왜 스레드를 사용할까?
- 동시성(Concurrency): 하나의 프로그램 안에서 여러 작업을 병렬적으로 실행
- 자원 공유: 같은 메모리 공간을 쓰므로 통신이 빠름
- 가벼움: 프로세스보다 생성과 전환 비용이 적음

### 예시
웹 서버는 클라이언트마다 스레드를 생성해 요청을 처리할 수 있음 → 여러 사용자가 동시에 접속해도 효율적으로 처리 가능

## 메모리 할당 (Memory Allocation)
운영체제는 실행 중인 프로그램에게 필요한 만큼 메모리를 동적으로 할당. 이 과정을 메모리 할당(Memory Allocation)이라 한다.

### 주요 방식
1. 정적 할당 (Static Allocation)
    - 컴파일 타임에 메모리 크기 고정
    - 예: 전역 변수, 정적 배열
2. 스택 할당 (Stack Allocation)
    - 함수 호출 시 지역 변수 저장
    - LIFO 구조 → 함수 종료 시 자동 해제
3. 힙 할당 (Heap Allocation)
    - 실행 중 동적으로 메모리 요청 (malloc, new 등)
    - 명시적 해제가 필요 (free, delete)

### 페이징과 세그멘테이션
운영체제는 메모리 공간을 효율적으로 관리하기 위해, 논리 주소(가상 주소)를 물리 주소로 변환하는 구조를 사용하는데 이 과정에서 대표적인 기법이 바로 페이징과 세그멘테이션

#### 페이징 (Paging)
- 개념
    - 가상 주소 공간과 물리 주소 공간을 고정된 크기(예: 4KB)의 블록 단위로 나누는 방식
    - 가상 메모리 → 페이지(Page)
    - 물리 메모리 → 프레임(Frame)
    - 페이지는 물리 메모리의 아무 프레임에나 비연속적으로 매핑 가능
- 동작 구조
```text
가상 주소 → [페이지 번호 | 오프셋]
           → 페이지 테이블 참조 → 물리 프레임 번호 + 오프셋 → 물리 주소
```
- 장점
    - 외부 단편화 없음 (모든 블록이 동일 크기)
    - 메모리 효율 증가
    - 가상 메모리 구현 용이

- 단점
    - 내부 단편화 발생 가능 (마지막 페이지 일부 미사용)
    - 페이지 테이블로 인한 오버헤드
    - TLB(Translation Lookaside Buffer) 같은 캐시 필요

> TLB(변환 후속 버퍼)는 가상 주소를 물리 주소로 빠르게 변환하기 위해 사용하는 고속 캐시 메모리
> 
> 운영체제는 페이지 테이블을 이용해 가상 주소 → 물리 주소로 변환. 하지만 이 페이지 테이블은 메인 메모리(RAM)에 있기 때문에 매번 접근하면 속도가 느려짐.
> 
> ➡ 이를 해결하기 위해 최근 사용한 주소 변환 정보를 TLB에 캐싱함으로써 주소 변환 속도를 크게 향상시킴

#### 세그멘테이션 (Segmentation)
- 개념
    - 프로세스의 논리적 구조에 따라 메모리를 가변 크기 블록으로 나누는 방식
    - 예: 코드, 데이터, 스택, 힙 → 각각 별도의 세그먼트(Segment)
- 동작 구조
```text
가상 주소 → [세그먼트 번호 | 오프셋]
           → 세그먼트 테이블 참조 → 시작 주소 + 오프셋 → 물리 주소
```
- 장점
    - 논리적 구조 반영 (코드, 데이터, 스택 구분)
    - 접근 권한 부여 용이 (세그먼트별로 read-only 등 설정 가능)
    - 내부 단편화 없음
- 단점
    - 외부 단편화 발생 가능 (가변 크기 때문에)
    - 복잡한 메모리 관리 필요


## 페이지 교체 알고리즘
가상 메모리에서는 필요한 페이지가 메모리에 없을 때 디스크에서 가져오는 과정(페이지 폴트)이 발생. 이때 기존 페이지 중 하나를 제거해야 하는데, 어떤 페이지를 제거할지를 결정하는 것이 페이지 교체 알고리즘

1. FIFO (First-In, First-Out)
- 원리
    - 가장 먼저 들어온 페이지를 먼저 제거
- 장점
    - 구현이 가장 단순
- 단점
    - Belady's Anomaly: 프레임 수가 늘어나도 미스가 늘 수 있음 (일반적인 캐시 논리에 반함)
- 예시
```text
프레임: 3  
입력: A B C D → 캐시 상태: [A B C] → D가 오면 A 제거 → [B C D]
```
2. LRU (Least Recently Used)
- 원리
    - 가장 오랫동안 사용되지 않은 페이지를 제거 (시간 지역성에 기반)
- 장점
    - 실제 사용 패턴과 유사
- 단점
    - 구현이 복잡 (시간 스탬프, 스택, 해시맵 등 필요)
- 예시
```text
입력: A B C A D  
프레임: 3  
[A B C] → A는 최근 사용됨 → D 삽입 시 B 제거 → [C A D]
```
3. Clock (Second Chance)
- 원리
    - LRU를 단순화한 알고리즘
    - 각 페이지에 사용 비트(Use Bit)를 부여하고, 1이면 비트를 0으로 바꾸고 다음으로 넘김. 0이면 교체
- 장점
    - 성능과 구현의 균형
    - 실제 OS에서 많이 사용
- 단점
    - 정확한 LRU는 아님
- 예시
```text
프레임: [A(1), B(0), C(1)]  
포인터 → B → 사용되지 않음 → B 제거  
```

4. LFU (Least Frequently Used)
- 원리
    - 사용 횟수가 가장 적은 페이지를 제거
- 장점
    - 장기적으로 덜 쓰는 데이터 제거
- 단점
    - 최근 사용 여부는 반영되지 않음
    - 기아(Starvation) 문제: 자주 쓰인 오래된 데이터가 계속 남음

5. Optimal
- 원리
    - 앞으로 가장 늦게 사용될 페이지를 제거 (이론적으로 가장 적은 페이지 폴트를 발생시킴)

- 장점
    - 최적의 성능

- 단점
    - 미래를 예측할 수 없기 때문에 실제 구현 불가능
    - 시뮬레이션이나 비교 기준으로만 사용