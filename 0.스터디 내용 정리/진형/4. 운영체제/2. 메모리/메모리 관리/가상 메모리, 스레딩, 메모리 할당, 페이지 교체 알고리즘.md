# 운영체제의 핵심 개념 정리

## 1. 가상 메모리 (Virtual Memory)

### 개념 설명
가상 메모리는 물리적 메모리(RAM)의 한계를 극복하기 위해 운영체제가 제공하는 **논리적인 메모리 공간**입니다.  
실제 RAM에 모두 올라와 있지 않아도, 각 프로세스가 마치 자신만의 연속된 주소 공간을 가진 것처럼 동작하게 해 주는 기술입니다.

### 왜 필요한가
- RAM 용량이 한정되어 있음에도 여러 프로그램을 동시에 실행해야 함
- 부족한 RAM을 보완하기 위해 **하드디스크 일부를 스왑 공간**으로 사용
- 프로세스마다 독립된 주소 공간을 제공하여 **메모리 보호** 및 **다중 작업** 지원

### 예시
- 책상에 올려둘 수 있는 책(RAM)이 부족할 때,  
  필요한 책만 꺼내 쓰고 나머지는 책장(디스크 스왑 공간)에 보관하는 것과 유사

### 가상 메모리의 동작 원리
- 가상 메모리의 동작 원리는 크게 **페이징**과 **세그멘테이션** 두 가지 방식으로 이루어지고,
  페이징 방식이 더 일반적이다

## 1-1. 페이징
- 페이징은 가상 메모리와 물리적 메모리를 **페이지(Page)**라는 작은 **고정 크기**의 블록으로 나누는 방식.
  운영체제는 프로그램이 필요로 하는 메로리를 페이지 단위로 관리하며, 필요한 페이지만 물리 메모리에 적재함.

- **페이지** : **가상 메모리**의 일정 크기 단위 (보통 4KB 또는 8KB)로 나눈 블록.
- **프레임** : **물리 메모리**의 일정 크기 단위로 나눈 블록으로, 페이지와 크기가 동일.
- **페이지 테이블** : 각 프로세스의 가상 주소와 실제 물리 주소를 매핑하는 테이블.
  가상 메모리 시스템에서는 프로세스의 가상 주소를 물리 주소로 변환해야 하며, 이 작업을 페이지 테이블이 담당함.

### 페이징 시스템의 동작 과정
1. 가상 주소 -> 물리 주소 변환 : 프로그램이 데이터를 읽거나 쓸 때 가상 주소를 참조함.CPU는 가상 주소를 물리 주소로 변환해야 하며, 이를 위해 페이지 테이블을 참조함.
2. 페이지 부재(Page Fault) : 프로그램이 접근하려는 페이지가 현재 물리 메모리에 없으면 페이지 부재가 발생함.
   이때 운영체제는 하드디스크에서 해당 페이지를 물리 메모리로 로드함.
3. 교체 정책 : 물리 메모리가 꽉 찼을 때는, 새로운 페이지를 불러오기 위해 기존의 페이지 중 하나를 내보내야 함.
   이를 페이지 **교체 알고리즘**이 결정함. **LRU(Least Recently used)**, **FIFO(First In, First Out)** 같은 기법을 사용함.

## 1-2. 세그멘테이션

- 페이징과 달리 가상 메모리를 논리적으로 **크기가 다른 세그먼트 (가변)**로 나누는 방식.
  프로그램은 코드, 데이터, 스택 등의 메모리 공간을 각각 다른 세그먼트로 구분하여 관리함.
  장점으로 논리적인 구분이 명확하다는 점이지만, 페이징 만큼은 효율적이지 않음

### 가상 메모리의 장점
1. 메모리 확장 : 물리적 메모리의 크기를 넘어서는 대용량 프로그램이 실행이 가능함. 프로그램이 실제로 사용하는 메모리보다 더 많은 가상 주소 공간을 할당할 수 있음.
2. 메모리 보호 : 각 프로세스는 독립된 가상 메모리 주소 공간을 가지므로, 한 프로세스가 다른 프로세스의 메모리에 접근하는 것을 방지할 수 있음
3. 효율적인 메모리 사용 : 프로그램이 필요한 부분만 물리 메모리에 적재하기 때문에, 전체 프로그램을 물리 메모리에 모두 적재하지 않아도 실행할 수 있다.
4. 다중 프로세스 실행 : 여러 프로그램이 동시에 실행될 때, 각 프로그램에 고유한 가상 주소 공간을 할당하여 충돌을 방지하고, 메모리 사용량을 효율적으로 관리할 수 있음.

### 가상 메모리의 단점

1. 페이지 부재 비용 : 페이지 부재가 발생하면 디스크에서 데이터를 가져와야 하기 때문에 속도가 느려질 수 있음
2. 복잡성 : 가상 메모리 시스템은 페이지 테이블을 관리하고, 페이지 교체 알고리즘을 구현해야 해서 시스템 복잡성이 증가함
3. 디스크 의존성 : HDD에서 메모리는 읽는 속도는 RAM보다 훨씬 느리므로, 가상 메모리를 너무 많이 사용하면 성능 하락이 발생함

### 단편화 (Fragmentation)
1. 페이징 : 페이지의 크기가 고정되어 있기 때문에 **외부 단편화 (External Fragmentation)** 문제는 발생하지 않음.
   하지만 고정 크기 때문에 마지막 페이지에 사용되지 않는 공간이 발생하는 **내부 단편화(Internal Fragmentation)** 문제가 생길 수 있다.
2. 세그먼테이션 : **가변 크기**의 세그먼트를 사용하기 때문에 내부 단편화는 발생하지 않지만, 메모리에 빈 공간이 생기면서 사용할 수 있는 공간이 여러 조각으로 나뉘는 **외부 단편화** 문제가 발생함.

---

## 2. 스레드 (Threading)

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FbOhMqd%2FbtqU4A6PJ2R%2FAAAAAAAAAAAAAAAAAAAAAETgqjKqZZxPyLeWCcU5xSsUSoLpl7sQuJPZaZWEhaBr%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1756652399%26allow_ip%3D%26allow_referer%3D%26signature%3Dkr%252FhOzdWvq6lj6jYeg8%252F3plaOVc%253D)

### 프로그램과 프로세스 차이 (클래스와 객의 관계)
- 프로그램 : Positive Entity. 명령어 리스트를 지닌 실행 파일 클래스 (정적 코드와 데이터의 집합)
- 프로세스 : Active Entity. 메모리에 적재되어 프로그램 카운터와 자원을 가진 인스턴스

### 프로세스와 스레드의 차이점
- 프로세스 : OS로 부터 자원을 할당받는 작업의 단위
- 스레드 : 프로세스가 할당받은 자원을 이용하는 실행의 단위

### 개념 설명
- 프로세스의 특성을 가지고 있기 떄문에 경량 프로세스(LWP, LightWeight Process)라고도 함.
- 스레드는 하나의 프로세스 내부에서 **실제 작업을 수행하는 실행 단위**입니다.
- 스레드끼리는 **코드·데이터·메모리** 자원을 공유하면서, 각자 독립된 **스택과 레지스터** 집합을 가집니다.
- 하나의 프로세스는 여러개의 스레드를 가질 수 있으며, 이를 **멀티 스레드** 라고 함

### 왜 필요한가
- 하나의 프로그램이 **동시에 여러 작업**을 처리하여 응답성 향상
- I/O 대기 중인 스레드가 있어도 다른 스레드가 CPU를 사용 가능
- 프로세스 전환보다 가벼운 **스레드 전환**으로 자원 효율성 증대

### 장점
- 자원 공유를 통해 시스템 자원 소모를 줄일 수 있음. Context Switch에 대한 오버헤드 감소

### 단점
- 동기화 문제가 발생할 수 있음. 프로그램 디버깅이 어려움.

### 관련 용어
- **프로세스(Process)**: 독립된 메모리 공간을 가진 실행 단위
- **멀티스레딩(Multi-threading)**: 하나의 프로세스 내에 여러 스레드를 두어 작업 분할
- **컨텍스트 스위칭(Context Switching)**: 실행 중인 스레드나 프로세스의 상태를 저장·복원하여 전환

---

## 3. 메모리 할당 (Memory Allocation)

### 개념 설명
운영체제가 프로세스에게 **메모리 공간을 나누어 주고 관리**하는 기능입니다.  
프로세스의 요청에 따라 메모리를 할당하고, 사용이 끝나면 해제하여 **재사용**할 수 있게 합니다.

### 왜 필요한가
- 메모리 충돌 방지 및 **안정성 확보**
- 사용하지 않는 메모리 회수로 **자원 낭비 최소화**
- 서로 다른 할당 정책(연속 vs. 불연속, 고정 분할 vs. 가변 분할)으로 **성능 최적화**

### 예시
- 호텔 방 배정:
    - 빈 방(메모리)을 손님(프로세스)에게 배정하고, 체크아웃 시 방을 청소(해제)하여 다음 손님에게 배정

### 관련 용어
- **단편화(Fragmentation)**
    - 외부 단편화: 메모리 조각들이 흩어져 큰 블록 확보 어려움
    - 내부 단편화: 할당된 블록 내 사용되지 않는 공간 발생
- **힙(Heap)**: 동적 할당 영역
- **스택(Stack)**: 함수 호출·지역 변수용 영역

---

## 4. 페이지 교체 알고리즘 (Page Replacement Algorithm)

### 개념 설명
메모리에 빈 프레임이 없을 때, **어떤 페이지를 디스크 스왑 영역으로 내보내고** 새 페이지를 적재할지 결정하는 전략입니다.

### 왜 필요한가
- 잘못된 교체로 인해 **반복적 페이지 폴트** 발생 시 성능 저하
- 디스크 I/O를 줄이고 **쓰레싱(Thrashing)** 방지

### 예시
- 책상에 펼쳐둔 책을 교체할 때:
    - **FIFO**: 가장 먼저 올려둔 책부터 치움
    - **LRU**: 가장 오랫동안 보지 않은 책을 치움

### 관련 용어
- **FIFO (First In First Out)**
- **LRU (Least Recently Used)**
- **OPT (Optimal)**: 이론상 가장 오래 사용되지 않을 페이지 교체
- **LFU (Least Frequently Used)**
- **쓰레싱(Thrashing)**: 지나친 페이지 교체로 유용 작업 불가

### 대표 페이지 교체 알고리즘

#### 1. FIFO (First In First Out)
- **개념**: 가장 먼저 메모리에 적재된 페이지를 가장 먼저 교체하는 방식.
- **동작 원리**: 페이지를 큐(Queue)에 삽입하고, 교체 시 큐의 맨 앞(가장 오래된 페이지)을 제거하여 새로운 페이지를 적재.
- **장점**: 구현이 간단하며 추가적인 메타데이터가 필요 없음.
- **단점**: Belady’s anomaly가 발생할 수 있어, 프레임 수를 늘려도 페이지 폴트가 줄어들지 않을 수 있음.

#### 2. LRU (Least Recently Used)
- **개념**: 가장 오랫동안 참조되지 않은 페이지를 교체하는 방식.
- **동작 원리**: 각 페이지의 마지막 참조 시점을 기록하거나, 해시와 이중 연결 리스트를 이용해 최근 사용된 순서를 관리.
- **장점**: 참조 패턴의 지역성(Locality)을 잘 반영하여 페이지 폴트를 효과적으로 줄임.
- **단점**: 구현 복잡도가 높아질 수 있으며, 카운터나 리스트 갱신에 오버헤드 발생.

#### 3. OPT (Optimal)
- **개념**: 이론적으로 가장 나중에 참조될 페이지를 교체하여 페이지 폴트를 최소화하는 최적 알고리즘.
- **동작 원리**: 미래의 참조 순서를 미리 알고 있다고 가정하고, 가장 오랫동안 사용되지 않을 페이지를 교체.
- **장점**: 페이지 폴트 횟수를 최소화하는 최적의 성능.
- **단점**: 실제 시스템에서 미래 참조를 예측할 수 없어, 시뮬레이션 용도로만 사용됨.

#### 4. LFU (Least Frequently Used)
- **개념**: 참조 횟수가 가장 적은 페이지를 교체하는 방식.
- **동작 원리**: 각 페이지에 대한 참조 횟수 카운터를 유지하고, 교체 시 가장 작은 카운터 값을 가진 페이지를 제거.
- **장점**: 오랫동안 거의 참조되지 않은 페이지를 우선 교체하여 장기적인 참조 패턴을 반영.
- **단점**: 카운터 유지·갱신 비용이 들며, 한때 자주 사용된 후 더 이상 사용되지 않는 페이지가 오래 남을 수 있음.

----

++ ipc 정리하면 좋을 것 같

Reference : https://yoongrammer.tistory.com/55